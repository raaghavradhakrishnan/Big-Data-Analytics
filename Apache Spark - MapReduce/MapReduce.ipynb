{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Raaghav Radhakrishnan - 246097"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Part (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZUmBLY39EAQr"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IofcczNEgJk"
   },
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utRm0e8dFYWC"
   },
   "outputs": [],
   "source": [
    "#List of words\n",
    "a = [\"spark\",\"rdd\",\"python\",\"context\",\"create\",\"class\"]\n",
    "b = [\"operation\", \"apache\", \"scala\", \"lambda\",\"parallel\",\"partition\"]\n",
    "\n",
    "#Making RDDs\n",
    "rdd_A = sc.parallelize(a)\n",
    "rdd_B= sc.parallelize(b)\n",
    "\n",
    "#Mapping the names of RDD\n",
    "A = rdd_A.map(lambda x: Row(name = x))\n",
    "B = rdd_B.map(lambda x: Row(name = x))\n",
    "\n",
    "#Creating dataframe from RDD\n",
    "dfA = sqlContext.createDataFrame(A)\n",
    "dfB = sqlContext.createDataFrame(B)\n",
    "\n",
    "#Creating Alias\n",
    "df1 = dfA.alias(\"df1\")\n",
    "df2 = dfB.alias(\"df2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right outer join:\n",
    "A RIGHT OUTER JOIN is one of the JOIN operations that allow you to specify a JOIN clause. It preserves the unmatched rows from the second (right) table, joining them with a NULL in the shape of the first (left) table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "q-0aaQhLi4HW",
    "outputId": "8235b7a9-1209-4eaf-86ae-066a7048c79e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Outer Join:\n",
      "+---------+\n",
      "|     name|\n",
      "+---------+\n",
      "|operation|\n",
      "|   lambda|\n",
      "|partition|\n",
      "| parallel|\n",
      "|    scala|\n",
      "|   apache|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Right Outer Join\n",
    "right_outer = df1.join(other=df2,on=\"name\",how='right_outer')\n",
    "print(\"Right Outer Join:\")\n",
    "right_outer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full outer join:\n",
    "A FULL OUTER JOIN combines the results of both left and right outer joins and returns all (matched or unmatched) rows from the tables on both sides of the join clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "qrYDWHLai-od",
    "outputId": "a5f3485e-f591-4605-ffb7-a295c0d78fed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Outer Join:\n",
      "+---------+\n",
      "|     name|\n",
      "+---------+\n",
      "|operation|\n",
      "|   lambda|\n",
      "|  context|\n",
      "|partition|\n",
      "|   create|\n",
      "|      rdd|\n",
      "| parallel|\n",
      "|    scala|\n",
      "|   apache|\n",
      "|    spark|\n",
      "|    class|\n",
      "|   python|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Full Outer Join\n",
    "full_outer = df1.join(other=df2,on=\"name\",how='full_outer')\n",
    "print(\"Full Outer Join:\")\n",
    "full_outer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "-cXW6nUijC9f",
    "outputId": "f5ce74ef-913a-4d2b-8f41-f41e6567f407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped Dataframe with count of 's'\n",
      "+----+\n",
      "|name|\n",
      "+----+\n",
      "|   0|\n",
      "|   0|\n",
      "|   0|\n",
      "|   0|\n",
      "|   0|\n",
      "|   0|\n",
      "|   0|\n",
      "|   1|\n",
      "|   0|\n",
      "|   1|\n",
      "|   2|\n",
      "|   0|\n",
      "+----+\n",
      "\n",
      "Using Map-Reduce, the character \"s\" appears 4 times in all a and b.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mapping the RDD\n",
    "map_rdd = full_outer.rdd.map(lambda x: sum([word.count('s') for word in x]))\n",
    "map_df = map_rdd.map(lambda x: Row(name = x))\n",
    "map_df = sqlContext.createDataFrame(map_df)\n",
    "print(\"Mapped Dataframe with count of 's'\")\n",
    "map_df.show()\n",
    "\n",
    "#Reducing the RDD\n",
    "reduce_rdd=map_rdd.reduce(lambda x,y: x+y)\n",
    "print(\"Using Map-Reduce, the character \\\"s\\\" appears\",reduce_rdd,\"times in all \n",
    "                                                                  a and b.\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6YCQFAq-jHpj",
    "outputId": "33785c1c-fb8d-44d4-a440-a9cf77eb8945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregate function, the character \"s\" appears 4 times in all a and b.\n"
     ]
    }
   ],
   "source": [
    "#Aggregate function\n",
    "count = full_outer.rdd.aggregate(0, lambda i, x: i + x[0].count('s'), \n",
    "                                 lambda i, j: i+j)\n",
    "print(\"Using aggregate function, the character \\\"s\\\" appears\",count,\n",
    "      \"times in all a and b.\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Part (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "t3ZOyJHWEUKR",
    "outputId": "aee94c31-33ce-48be-dd25-50a3b8986f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students records: \n",
      "\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "|            course|               dob|first_name|last_name|points|s_id|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "|Humanities and Art|  October 14, 1983|      Alan|      Joe|    10|   1|\n",
      "|  Computer Science|September 26, 1980|    Martin|  Genberg|    17|   2|\n",
      "|    Graphic Design|     June 12, 1982|     Athur|   Watson|    16|   3|\n",
      "|    Graphic Design|     April 5, 1987|  Anabelle|  Sanberg|    12|   4|\n",
      "|        Psychology|  November 1, 1978|      Kira| Schommer|    11|   5|\n",
      "|          Business|  17 February 1981| Christian|   Kiriam|    10|   6|\n",
      "|  Machine Learning|    1 January 1984|   Barbara|  Ballard|    14|   7|\n",
      "|     Deep Learning|  January 13, 1978|      John|     null|    10|   8|\n",
      "|  Machine Learning|  26 December 1989|    Marcus|   Carson|    15|   9|\n",
      "|           Physics|  30 December 1987|     Marta|   Brooks|    11|  10|\n",
      "|    Data Analytics|     June 12, 1975|     Holly| Schwartz|    12|  11|\n",
      "|  Computer Science|      July 2, 1985|     April|    Black|  null|  12|\n",
      "|  Computer Science|     July 22, 1980|     Irene|  Bradley|    13|  13|\n",
      "|        Psychology|   7 February 1986|      Mark|    Weber|    12|  14|\n",
      "|       Informatics|      May 18, 1987|     Rosie|   Norman|     9|  15|\n",
      "|          Business|   August 10, 1984|    Martin|   Steele|     7|  16|\n",
      "|  Machine Learning|  16 December 1990|     Colin| Martinez|     9|  17|\n",
      "|    Data Analytics|              null|   Bridget|    Twain|     6|  18|\n",
      "|          Business|      7 March 1980|   Darlene|    Mills|    19|  19|\n",
      "|    Data Analytics|      June 2, 1985|   Zachary|     null|    10|  20|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_file = \"gdrive/My Drive/DDA/Spark1/students.json\"\n",
    "df = sqlContext.read.json(json_file)\n",
    "print(\"Students records: \\n\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "YIhhaPa4Ecis",
    "outputId": "4658ff87-9e89-4626-e051-69e1e3e2feb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing the null values in column points by mean of all points: \n",
      "\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "|            course|               dob|first_name|last_name|points|s_id|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "|Humanities and Art|  October 14, 1983|      Alan|      Joe|    10|   1|\n",
      "|  Computer Science|September 26, 1980|    Martin|  Genberg|    17|   2|\n",
      "|    Graphic Design|     June 12, 1982|     Athur|   Watson|    16|   3|\n",
      "|    Graphic Design|     April 5, 1987|  Anabelle|  Sanberg|    12|   4|\n",
      "|        Psychology|  November 1, 1978|      Kira| Schommer|    11|   5|\n",
      "|          Business|  17 February 1981| Christian|   Kiriam|    10|   6|\n",
      "|  Machine Learning|    1 January 1984|   Barbara|  Ballard|    14|   7|\n",
      "|     Deep Learning|  January 13, 1978|      John|     null|    10|   8|\n",
      "|  Machine Learning|  26 December 1989|    Marcus|   Carson|    15|   9|\n",
      "|           Physics|  30 December 1987|     Marta|   Brooks|    11|  10|\n",
      "|    Data Analytics|     June 12, 1975|     Holly| Schwartz|    12|  11|\n",
      "|  Computer Science|      July 2, 1985|     April|    Black|    11|  12|\n",
      "|  Computer Science|     July 22, 1980|     Irene|  Bradley|    13|  13|\n",
      "|        Psychology|   7 February 1986|      Mark|    Weber|    12|  14|\n",
      "|       Informatics|      May 18, 1987|     Rosie|   Norman|     9|  15|\n",
      "|          Business|   August 10, 1984|    Martin|   Steele|     7|  16|\n",
      "|  Machine Learning|  16 December 1990|     Colin| Martinez|     9|  17|\n",
      "|    Data Analytics|              null|   Bridget|    Twain|     6|  18|\n",
      "|          Business|      7 March 1980|   Darlene|    Mills|    19|  19|\n",
      "|    Data Analytics|      June 2, 1985|   Zachary|     null|    10|  20|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean,col\n",
    "avg = df.select(mean(col('points')).alias('mean')).collect()\n",
    "df = df.na.fill(avg[0]['mean'])\n",
    "print(\"Replacing the null values in column points by mean of all points: \\n\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "3CIrLD6Nik7A",
    "outputId": "1b2b2bc1-228b-463e-ceb5-898faa732006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing values in column dob and last_name by 'unknown' and '--': \n",
      "\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "|            course|               dob|first_name|last_name|points|s_id|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "|Humanities and Art|  October 14, 1983|      Alan|      Joe|    10|   1|\n",
      "|  Computer Science|September 26, 1980|    Martin|  Genberg|    17|   2|\n",
      "|    Graphic Design|     June 12, 1982|     Athur|   Watson|    16|   3|\n",
      "|    Graphic Design|     April 5, 1987|  Anabelle|  Sanberg|    12|   4|\n",
      "|        Psychology|  November 1, 1978|      Kira| Schommer|    11|   5|\n",
      "|          Business|  17 February 1981| Christian|   Kiriam|    10|   6|\n",
      "|  Machine Learning|    1 January 1984|   Barbara|  Ballard|    14|   7|\n",
      "|     Deep Learning|  January 13, 1978|      John|       --|    10|   8|\n",
      "|  Machine Learning|  26 December 1989|    Marcus|   Carson|    15|   9|\n",
      "|           Physics|  30 December 1987|     Marta|   Brooks|    11|  10|\n",
      "|    Data Analytics|     June 12, 1975|     Holly| Schwartz|    12|  11|\n",
      "|  Computer Science|      July 2, 1985|     April|    Black|    11|  12|\n",
      "|  Computer Science|     July 22, 1980|     Irene|  Bradley|    13|  13|\n",
      "|        Psychology|   7 February 1986|      Mark|    Weber|    12|  14|\n",
      "|       Informatics|      May 18, 1987|     Rosie|   Norman|     9|  15|\n",
      "|          Business|   August 10, 1984|    Martin|   Steele|     7|  16|\n",
      "|  Machine Learning|  16 December 1990|     Colin| Martinez|     9|  17|\n",
      "|    Data Analytics|           unknown|   Bridget|    Twain|     6|  18|\n",
      "|          Business|      7 March 1980|   Darlene|    Mills|    19|  19|\n",
      "|    Data Analytics|      June 2, 1985|   Zachary|       --|    10|  20|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.na.fill({'dob':'unknown','last_name':'--'})\n",
    "print(\"Replacing values in column dob and last_name by 'unknown' and '--': \\n\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hM076HfdgwS3"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean,col\n",
    "avg = df.select(mean(col('points')).alias('mean')).collect()\n",
    "df = df.na.fill({'dob':'January 20, 1995','last_name':'--'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "imtmKXk7Nfx5",
    "outputId": "d41613ba-49f4-4d6c-e628-aa7570bff59c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates changed to 'DD-MM-YYYY' format: \n",
      "\n",
      "+------------------+----------+----------+---------+------+----+\n",
      "|            course|       dob|first_name|last_name|points|s_id|\n",
      "+------------------+----------+----------+---------+------+----+\n",
      "|Humanities and Art|14-10-1983|      Alan|      Joe|    10|   1|\n",
      "|  Computer Science|26-09-1980|    Martin|  Genberg|    17|   2|\n",
      "|    Graphic Design|12-06-1982|     Athur|   Watson|    16|   3|\n",
      "|    Graphic Design|05-04-1987|  Anabelle|  Sanberg|    12|   4|\n",
      "|        Psychology|01-11-1978|      Kira| Schommer|    11|   5|\n",
      "|          Business|17-02-1981| Christian|   Kiriam|    10|   6|\n",
      "|  Machine Learning|01-01-1984|   Barbara|  Ballard|    14|   7|\n",
      "|     Deep Learning|13-01-1978|      John|       --|    10|   8|\n",
      "|  Machine Learning|26-12-1989|    Marcus|   Carson|    15|   9|\n",
      "|           Physics|30-12-1987|     Marta|   Brooks|    11|  10|\n",
      "|    Data Analytics|12-06-1975|     Holly| Schwartz|    12|  11|\n",
      "|  Computer Science|02-07-1985|     April|    Black|    11|  12|\n",
      "|  Computer Science|22-07-1980|     Irene|  Bradley|    13|  13|\n",
      "|        Psychology|07-02-1986|      Mark|    Weber|    12|  14|\n",
      "|       Informatics|18-05-1987|     Rosie|   Norman|     9|  15|\n",
      "|          Business|10-08-1984|    Martin|   Steele|     7|  16|\n",
      "|  Machine Learning|16-12-1990|     Colin| Martinez|     9|  17|\n",
      "|    Data Analytics|20-01-1995|   Bridget|    Twain|     6|  18|\n",
      "|          Business|07-03-1980|   Darlene|    Mills|    19|  19|\n",
      "|    Data Analytics|02-06-1985|   Zachary|       --|    10|  20|\n",
      "+------------------+----------+----------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dateutil import parser\n",
    "import datetime\n",
    "from pyspark.sql.types import TimestampType,DateType\n",
    "from pyspark.sql.functions import UserDefinedFunction,col,date_format\n",
    "udf = UserDefinedFunction(lambda x:parser.parse(x), TimestampType())\n",
    "ts_df = df.withColumn(\"dob_timestamp\",udf(df.dob))\n",
    "func = UserDefinedFunction(lambda x: datetime.datetime\n",
    "                           .strptime(str(x), '%Y-%m-%d %H:%M:%S'), \n",
    "                           TimestampType())\n",
    "\n",
    "df_upd = ts_df.withColumn('dob', date_format(func(col('dob_timestamp')), \n",
    "                                             'dd-MM-yyyy'))\n",
    "dd = df_upd.drop('dob_timestamp')\n",
    "print(\"Dates changed to 'DD-MM-YYYY' format: \\n\")\n",
    "dd.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "2QL3Ed0MEfns",
    "outputId": "8c8a7723-c92e-4d0c-dda2-d023b7980d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated records with the current age of students: \n",
      "\n",
      "+------------------+----------+----------+---------+------+----+---+\n",
      "|            course|       dob|first_name|last_name|points|s_id|age|\n",
      "+------------------+----------+----------+---------+------+----+---+\n",
      "|Humanities and Art|14-10-1983|      Alan|      Joe|    10|   1| 36|\n",
      "|  Computer Science|26-09-1980|    Martin|  Genberg|    17|   2| 39|\n",
      "|    Graphic Design|12-06-1982|     Athur|   Watson|    16|   3| 37|\n",
      "|    Graphic Design|05-04-1987|  Anabelle|  Sanberg|    12|   4| 32|\n",
      "|        Psychology|01-11-1978|      Kira| Schommer|    11|   5| 41|\n",
      "|          Business|17-02-1981| Christian|   Kiriam|    10|   6| 38|\n",
      "|  Machine Learning|01-01-1984|   Barbara|  Ballard|    14|   7| 35|\n",
      "|     Deep Learning|13-01-1978|      John|       --|    10|   8| 41|\n",
      "|  Machine Learning|26-12-1989|    Marcus|   Carson|    15|   9| 30|\n",
      "|           Physics|30-12-1987|     Marta|   Brooks|    11|  10| 32|\n",
      "|    Data Analytics|12-06-1975|     Holly| Schwartz|    12|  11| 44|\n",
      "|  Computer Science|02-07-1985|     April|    Black|    11|  12| 34|\n",
      "|  Computer Science|22-07-1980|     Irene|  Bradley|    13|  13| 39|\n",
      "|        Psychology|07-02-1986|      Mark|    Weber|    12|  14| 33|\n",
      "|       Informatics|18-05-1987|     Rosie|   Norman|     9|  15| 32|\n",
      "|          Business|10-08-1984|    Martin|   Steele|     7|  16| 35|\n",
      "|  Machine Learning|16-12-1990|     Colin| Martinez|     9|  17| 29|\n",
      "|    Data Analytics|20-01-1995|   Bridget|    Twain|     6|  18| 24|\n",
      "|          Business|07-03-1980|   Darlene|    Mills|    19|  19| 39|\n",
      "|    Data Analytics|02-06-1985|   Zachary|       --|    10|  20| 34|\n",
      "+------------------+----------+----------+---------+------+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit,year\n",
    "df_upd = df_upd.withColumn('age',2019 - year(col('dob_timestamp')))\n",
    "df_upd = df_upd.drop('dob_timestamp')\n",
    "print(\"Updated records with the current age of students: \\n\")\n",
    "df_upd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "MM958iUaKmuM",
    "outputId": "1f4cd780-cb85-48b5-8ab5-66eba2c196f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated points using one standard deviation: \n",
      "\n",
      "+------------------+----------+----------+---------+------+----+---+\n",
      "|            course|       dob|first_name|last_name|points|s_id|age|\n",
      "+------------------+----------+----------+---------+------+----+---+\n",
      "|Humanities and Art|14-10-1983|      Alan|      Joe|    10|   1| 36|\n",
      "|  Computer Science|26-09-1980|    Martin|  Genberg|    20|   2| 39|\n",
      "|    Graphic Design|12-06-1982|     Athur|   Watson|    20|   3| 37|\n",
      "|    Graphic Design|05-04-1987|  Anabelle|  Sanberg|    12|   4| 32|\n",
      "|        Psychology|01-11-1978|      Kira| Schommer|    11|   5| 41|\n",
      "|          Business|17-02-1981| Christian|   Kiriam|    10|   6| 38|\n",
      "|  Machine Learning|01-01-1984|   Barbara|  Ballard|    14|   7| 35|\n",
      "|     Deep Learning|13-01-1978|      John|       --|    10|   8| 41|\n",
      "|  Machine Learning|26-12-1989|    Marcus|   Carson|    20|   9| 30|\n",
      "|           Physics|30-12-1987|     Marta|   Brooks|    11|  10| 32|\n",
      "|    Data Analytics|12-06-1975|     Holly| Schwartz|    12|  11| 44|\n",
      "|  Computer Science|02-07-1985|     April|    Black|    11|  12| 34|\n",
      "|  Computer Science|22-07-1980|     Irene|  Bradley|    13|  13| 39|\n",
      "|        Psychology|07-02-1986|      Mark|    Weber|    12|  14| 33|\n",
      "|       Informatics|18-05-1987|     Rosie|   Norman|     9|  15| 32|\n",
      "|          Business|10-08-1984|    Martin|   Steele|     7|  16| 35|\n",
      "|  Machine Learning|16-12-1990|     Colin| Martinez|     9|  17| 29|\n",
      "|    Data Analytics|20-01-1995|   Bridget|    Twain|     6|  18| 24|\n",
      "|          Business|07-03-1980|   Darlene|    Mills|    20|  19| 39|\n",
      "|    Data Analytics|02-06-1985|   Zachary|       --|    10|  20| 34|\n",
      "+------------------+----------+----------+---------+------+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import stddev as std\n",
    "from pyspark.sql.functions import when\n",
    "sd = df.select(std(col('points')).alias('std')).collect()\n",
    "sd = sd[0]['std']\n",
    "df_pnt = df_upd.withColumn('points',when(df_upd.points >= sd+avg[0]['mean'],20)\n",
    "                           .otherwise(df_upd.points))\n",
    "print(\"Updated points using one standard deviation: \\n\")\n",
    "df_pnt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "QtxlwhUjNcv9",
    "outputId": "199e2bbe-f982-4a45-84a4-1b006a299a2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram of new points: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCtyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pt = df_pnt.toPandas()['points']\n",
    "print(\"Histogram of new points: \\n\")\n",
    "plt.hist(pt,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQjg_20OEG7E"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import mean as avg,stddev as stdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the sessions of the user, the lags are found from which the \n",
    "difference in active time of the user is calculated. This is then checked if \n",
    "the user has exceeded 30 minutes are not. If yes, it's considered as timed-out \n",
    "session and if no, it's an active session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gS0giSoVpWxy",
    "outputId": "e794e204-e10a-492d-fc12-7655a77c0e5e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging session for each user: \n",
      "\n",
      "+------+-------+----------------+----------+-------+\n",
      "|UserID|MovieID|            Tags| Timestamp|session|\n",
      "+------+-------+----------------+----------+-------+\n",
      "|  6658|   2712|     unwatchable|1140486822|      0|\n",
      "|  6658|    288|        annoying|1140486947|      1|\n",
      "| 10817|    158| Christina Ricci|1218451667|      0|\n",
      "| 10817|   3826|     Kevin Bacon|1218452067|      1|\n",
      "| 10817|   3826|  elizabeth shue|1218452092|      2|\n",
      "| 10817|   7451|   Lindsay Lohan|1218452569|      3|\n",
      "| 10817|   1367|      glen close|1218466235|      3|\n",
      "| 12046|   1610|        cold war|1222049475|      0|\n",
      "| 12046|   1222|     Vietnam War|1222049571|      1|\n",
      "| 12046|    750|     dark comedy|1226230439|      1|\n",
      "| 12046|    750| Stanley Kubrick|1226230442|      2|\n",
      "| 12046|    750|        cold war|1226230454|      3|\n",
      "| 12046|    750|          satire|1226230466|      4|\n",
      "| 12046|    778|    imdb top 250|1226230555|      5|\n",
      "| 12046|    778|    black comedy|1226230582|      6|\n",
      "| 12046|  48774|end of the world|1226230975|      7|\n",
      "| 12046|  48774|             war|1226230978|      8|\n",
      "| 12046|  48774|    imdb top 250|1226230981|      9|\n",
      "| 12046|  48774|        dystopia|1226230983|     10|\n",
      "| 12046|  48774|      apocalypse|1226230992|     11|\n",
      "+------+-------+----------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "******************************************************\n",
      "\n",
      "\n",
      "Frequency of tagging: \n",
      "\n",
      "+------+------------+\n",
      "|UserID|max(session)|\n",
      "+------+------------+\n",
      "| 10555|         884|\n",
      "| 23172|         476|\n",
      "|   146|         332|\n",
      "| 33384|         243|\n",
      "| 47448|         198|\n",
      "| 34745|         143|\n",
      "| 11898|         126|\n",
      "| 30167|         114|\n",
      "| 64633|         107|\n",
      "|  8041|         103|\n",
      "| 41838|          99|\n",
      "|  6362|          94|\n",
      "| 23388|          84|\n",
      "| 18015|          77|\n",
      "| 23032|          72|\n",
      "| 49882|          72|\n",
      "| 59092|          71|\n",
      "| 50970|          70|\n",
      "|  2643|          68|\n",
      "| 32828|          64|\n",
      "+------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "******************************************************\n",
      "\n",
      "\n",
      "Mean and Standard deviation of the tagging frequency of\n",
      "each user: \n",
      "\n",
      "+------+------------------+--------------------+\n",
      "|UserID|      avg(session)|stddev_samp(session)|\n",
      "+------+------------------+--------------------+\n",
      "| 10555| 520.4491017964071|  226.60815651786262|\n",
      "| 23172|233.75731284085276|   143.7536630775717|\n",
      "|   146|127.94781553398059|    88.3217936310053|\n",
      "| 47448| 90.14512195121951|   66.04907830853023|\n",
      "| 11898| 61.71298174442191|   39.88577311890879|\n",
      "| 33384| 53.68281938325991|   71.10460757488028|\n",
      "| 34745| 52.15585443037975|   42.93201365252578|\n",
      "| 64633| 50.52549575070822|   34.70998468723264|\n",
      "| 41838|42.367198838896954|  31.872750688848402|\n",
      "|  6362|          42.28125|  25.116150339042868|\n",
      "| 23388| 37.94854586129754|  26.888318827426215|\n",
      "| 50970| 33.81666666666667|  20.285826861639716|\n",
      "|  8041| 33.44179104477612|   30.78448433585449|\n",
      "| 32828|28.953929539295395|  12.565504107840338|\n",
      "| 48621| 28.08076923076923|   16.96206349067229|\n",
      "| 19460|            27.875|  15.358259215357908|\n",
      "| 49882|27.476462196861625|   16.51963600542648|\n",
      "| 24221|  26.5472972972973|  13.190049901325256|\n",
      "| 39689| 26.10236220472441|  14.808746153191747|\n",
      "| 69388|25.571428571428573|  16.550370366667796|\n",
      "+------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "******************************************************\n",
      "\n",
      "\n",
      "Mean and Standard deviation of the tagging frequency\n",
      "across users: \n",
      "\n",
      "Mean:  56.551276417660596\n",
      "Standard Deviation:  146.6106950491872\n",
      "******************************************************\n",
      "\n",
      "\n",
      "List of users with a mean tagging frequency within two\n",
      "standard deviation from the mean frequency for across users: \n",
      "\n",
      "+------+\n",
      "|UserID|\n",
      "+------+\n",
      "| 43527|\n",
      "| 18979|\n",
      "| 24171|\n",
      "| 12046|\n",
      "| 36538|\n",
      "| 53565|\n",
      "| 65867|\n",
      "| 57380|\n",
      "| 10817|\n",
      "|  6658|\n",
      "| 14570|\n",
      "| 15846|\n",
      "| 16574|\n",
      "| 25462|\n",
      "| 26583|\n",
      "| 32445|\n",
      "| 41946|\n",
      "| 47711|\n",
      "| 49308|\n",
      "| 51123|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat_file = \"gdrive/My Drive/DDA/Spark1/tags.dat\"\n",
    "\n",
    "df = sqlContext.read.option(\"delimiter\",\":\").csv(dat_file)\n",
    "df = df.selectExpr(\"_c0 as UserID\",\"_c2 as MovieID\",\"_c4 as Tags\",\n",
    "                   \"_c6 as Timestamp\")\n",
    "df = df.withColumn(\"UserID\", df[\"UserID\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"MovieID\",df[\"MovieID\"].cast(IntegerType()))\n",
    "ts_w = Window.partitionBy(\"UserID\").orderBy(asc(\"Timestamp\"))\n",
    "df = df.withColumn('lag',lag(df.Timestamp).over(ts_w))\n",
    "df = df.withColumn('difference',when((df.Timestamp - df.lag)/60 < 30,1)\n",
    "                   .otherwise(0))\n",
    "df = df.withColumn('session',sum('difference').over(ts_w))\n",
    "df = df.drop('lag','difference')\n",
    "print(\"Tagging session for each user: \\n\")\n",
    "df.show()\n",
    "\n",
    "print(\"******************************************************\\n\\n\")\n",
    "\n",
    "df = df.withColumn('lag',lag(df.Timestamp).over(ts_w))\n",
    "df = df.withColumn('difference',when((df.Timestamp - df.lag) > 30*60,1)\n",
    "                   .otherwise(0))\n",
    "df = df.withColumn('session',sum('difference').over(ts_w))\n",
    "df = df.drop('lag','difference')\n",
    "\n",
    "max_freq = df.groupBy(\"UserID\").max(\"session\")\n",
    "max_freq = max_freq.orderBy('max(session)',ascending=False)\n",
    "print(\"Frequency of tagging: \\n\")\n",
    "max_freq.show()\n",
    "\n",
    "print(\"******************************************************\\n\\n\")\n",
    "\n",
    "m = df.groupBy(\"UserID\").mean(\"session\").orderBy('avg(session)',\n",
    "                                                 ascending=False)\n",
    "print(\"Mean and Standard deviation of the tagging frequency of\\neach user: \\n\")\n",
    "sd = df.groupBy(\"UserID\").agg(stddev(\"session\"))\n",
    "\n",
    "msd = m.join(sd,\"UserID\",how='right_outer').orderBy('avg(session)',\n",
    "                                                    ascending=False)\n",
    "msd.show()\n",
    "\n",
    "print(\"******************************************************\\n\\n\")\n",
    "\n",
    "mean = df.agg(avg(\"session\")).collect()[0]['avg(session)']\n",
    "std = df.agg(stdd(\"session\")).collect()[0]['stddev_samp(session)']\n",
    "print(\"Mean and Standard deviation of the tagging frequency\\nacross users: \\n\")\n",
    "print(\"Mean: \",mean)\n",
    "print(\"Standard Deviation: \",std)\n",
    "\n",
    "print(\"******************************************************\\n\\n\")\n",
    "print(\"List of users with a mean tagging frequency within two\\nstandard \\\n",
    "      deviation from the mean frequency for across users: \\n\")\n",
    "m = m.withColumn(\"Flag\",when(m['avg(session)'] < 2*std, 1).otherwise(0))\n",
    "users_list = m.filter(m.Flag == 1).select('UserID').distinct()\n",
    "users_list.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kpWNOuLbKnwz"
   },
   "source": [
    "### Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 890
    },
    "colab_type": "code",
    "id": "dSvWryVtesNn",
    "outputId": "f7faf2c8-6b66-47c0-b8db-32d09d197e15",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|MovieID|               Title|               Genre|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Animation|Childre...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|        Comedy|Drama|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|Adventure|Children's|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|             Dracula|                null|\n",
      "|     13|        Balto (1995)|Animation|Children's|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|      Drama|Thriller|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|            Thriller|\n",
      "|     19|         Ace Ventura|                null|\n",
      "|     20|  Money Train (1995)|              Action|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+-------+------+---------+\n",
      "|UserID|MovieID|Rating|Timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|   1193|     5|978300760|\n",
      "|     1|    661|     3|978302109|\n",
      "|     1|    914|     3|978301968|\n",
      "|     1|   3408|     4|978300275|\n",
      "|     1|   2355|     5|978824291|\n",
      "|     1|   1197|     3|978302268|\n",
      "|     1|   1287|     5|978302039|\n",
      "|     1|   2804|     5|978300719|\n",
      "|     1|    594|     4|978302268|\n",
      "|     1|    919|     4|978301368|\n",
      "|     1|    595|     5|978824268|\n",
      "|     1|    938|     4|978301752|\n",
      "|     1|   2398|     4|978302281|\n",
      "|     1|   2918|     4|978302124|\n",
      "|     1|   1035|     5|978301753|\n",
      "|     1|   2791|     4|978302188|\n",
      "|     1|   2687|     3|978824268|\n",
      "|     1|   2018|     4|978301777|\n",
      "|     1|   3105|     5|978301713|\n",
      "|     1|   2797|     4|978302039|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_dat_file = \"gdrive/My Drive/DDA/Spark1/movies.dat\"\n",
    "\n",
    "df_movie = sqlContext.read.option(\"delimiter\",\":\").csv(movies_dat_file)\n",
    "df_movie= df_movie.selectExpr(\"_c0 as MovieID\",\"_c2 as Title\",\"_c4 as Genre\")\n",
    "df_movie.show()\n",
    "\n",
    "ratings_dat_file = \"gdrive/My Drive/DDA/Spark1/ratings.dat\"\n",
    "\n",
    "df_ratings = sqlContext.read.option(\"delimiter\",\":\").csv(ratings_dat_file)\n",
    "df_ratings = df_ratings.selectExpr(\"_c0 as UserID\",\"_c2 as MovieID\",\n",
    "                                   \"_c4 as Rating\",\"_c6 as Timestamp\")\n",
    "df_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "qNQr-IPkqI37",
    "outputId": "18c67343-51a3-47ea-a480-3dc70ee3738d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+------+---------+\n",
      "|MovieID|               Title|               Genre|UserID|Rating|Timestamp|\n",
      "+-------+--------------------+--------------------+------+------+---------+\n",
      "|   1193|One Flew Over the...|               Drama|     1|     5|978300760|\n",
      "|    661|James and the Gia...|Animation|Childre...|     1|     3|978302109|\n",
      "|    914| My Fair Lady (1964)|     Musical|Romance|     1|     3|978301968|\n",
      "|   3408|Erin Brockovich (...|               Drama|     1|     4|978300275|\n",
      "|   2355|Bug's Life, A (1998)|Animation|Childre...|     1|     5|978824291|\n",
      "|   1197|Princess Bride, T...|Action|Adventure|...|     1|     3|978302268|\n",
      "|   1287|      Ben-Hur (1959)|Action|Adventure|...|     1|     5|978302039|\n",
      "|   2804|Christmas Story, ...|        Comedy|Drama|     1|     5|978300719|\n",
      "|    594|Snow White and th...|Animation|Childre...|     1|     4|978302268|\n",
      "|    919|Wizard of Oz, The...|Adventure|Childre...|     1|     4|978301368|\n",
      "|    595|Beauty and the Be...|Animation|Childre...|     1|     5|978824268|\n",
      "|    938|         Gigi (1958)|             Musical|     1|     4|978301752|\n",
      "|   2398|Miracle on 34th S...|               Drama|     1|     4|978302281|\n",
      "|   2918|Ferris Bueller's ...|              Comedy|     1|     4|978302124|\n",
      "|   1035|Sound of Music, T...|             Musical|     1|     5|978301753|\n",
      "|   2791|    Airplane! (1980)|              Comedy|     1|     4|978302188|\n",
      "|   2687|       Tarzan (1999)|Animation|Children's|     1|     3|978824268|\n",
      "|   2018|        Bambi (1942)|Animation|Children's|     1|     4|978301777|\n",
      "|   3105|   Awakenings (1990)|               Drama|     1|     5|978301713|\n",
      "|   2797|          Big (1988)|      Comedy|Fantasy|     1|     4|978302039|\n",
      "+-------+--------------------+--------------------+------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Merging both the dataframes\n",
    "merged = df_movie.join(df_ratings,'MovieID','inner')\n",
    "merged.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "Eq93v2TK1k3x",
    "outputId": "4e97763b-1be6-44b8-c333-6f78ae9e68c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|               Title|Rating|\n",
      "+--------------------+------+\n",
      "|One Flew Over the...|     5|\n",
      "|James and the Gia...|     3|\n",
      "| My Fair Lady (1964)|     3|\n",
      "|Erin Brockovich (...|     4|\n",
      "|Bug's Life, A (1998)|     5|\n",
      "|Princess Bride, T...|     3|\n",
      "|      Ben-Hur (1959)|     5|\n",
      "|Christmas Story, ...|     5|\n",
      "|Snow White and th...|     4|\n",
      "|Wizard of Oz, The...|     4|\n",
      "|Beauty and the Be...|     5|\n",
      "|         Gigi (1958)|     4|\n",
      "|Miracle on 34th S...|     4|\n",
      "|Ferris Bueller's ...|     4|\n",
      "|Sound of Music, T...|     5|\n",
      "|    Airplane! (1980)|     4|\n",
      "|       Tarzan (1999)|     3|\n",
      "|        Bambi (1942)|     4|\n",
      "|   Awakenings (1990)|     5|\n",
      "|          Big (1988)|     4|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['MovieID', 'Genre','UserID','Timestamp']\n",
    "test = merged.drop(*columns_to_drop)\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "ITO3u9YNCLJu",
    "outputId": "48d2de6d-66b3-48b3-e6d9-1b0bcce063e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with maximum average rating: \n",
      "\n",
      "+--------------------+----------+\n",
      "|             MovieID|Avg_Rating|\n",
      "+--------------------+----------+\n",
      "|Gate of Heavenly ...|       5.0|\n",
      "|Smashing Time (1967)|       5.0|\n",
      "|        Lured (1947)|       5.0|\n",
      "|One Little Indian...|       5.0|\n",
      "|    Baby, The (1973)|       5.0|\n",
      "|Schlafes Bruder (...|       5.0|\n",
      "|Follow the Bitch ...|       5.0|\n",
      "|Bittersweet Motel...|       5.0|\n",
      "|Ulysses (Ulisse) ...|       5.0|\n",
      "|Song of Freedom (...|       5.0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = test.withColumn(\"Rating\", test[\"Rating\"].cast(IntegerType()))\n",
    "a = test.rdd.groupByKey().mapValues(lambda x: sum(x) / len(x))\n",
    "c = sqlContext.createDataFrame(a).orderBy('_2',ascending = False)\n",
    "c = c.filter(c._2 == 5.0)\n",
    "c = c.selectExpr(\"_1 as MovieID\",\"_2 as Avg_Rating\")\n",
    "print(\"Movies with maximum average rating: \\n\")\n",
    "c.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "-q9WwGinCZKq",
    "outputId": "fec8c0b6-dbe2-4557-9d6c-d2edb912c8e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|               Genre|Rating|\n",
      "+--------------------+------+\n",
      "|               Drama|     5|\n",
      "|Animation|Childre...|     3|\n",
      "|     Musical|Romance|     3|\n",
      "|               Drama|     4|\n",
      "|Animation|Childre...|     5|\n",
      "|Action|Adventure|...|     3|\n",
      "|Action|Adventure|...|     5|\n",
      "|        Comedy|Drama|     5|\n",
      "|Animation|Childre...|     4|\n",
      "|Adventure|Childre...|     4|\n",
      "|Animation|Childre...|     5|\n",
      "|             Musical|     4|\n",
      "|               Drama|     4|\n",
      "|              Comedy|     4|\n",
      "|             Musical|     5|\n",
      "|              Comedy|     4|\n",
      "|Animation|Children's|     3|\n",
      "|Animation|Children's|     4|\n",
      "|               Drama|     5|\n",
      "|      Comedy|Fantasy|     4|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['MovieID', 'Title','UserID','Timestamp']\n",
    "test = merged.drop(*columns_to_drop)\n",
    "test.show()\n",
    "\n",
    "test = test.withColumn(\"Rating\", test[\"Rating\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "M19PKbqFChiN",
    "outputId": "4c1fb955-d3e8-41f1-ee72-83c137ff20d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|               Genre|        Avg_Rating|\n",
      "+--------------------+------------------+\n",
      "|Animation|Comedy|...| 4.473837209302325|\n",
      "|   Film-Noir|Mystery| 4.367424242424242|\n",
      "|       Adventure|War|  4.34610705596107|\n",
      "|Film-Noir|Romance...|  4.29438202247191|\n",
      "|    Film-Noir|Sci-Fi| 4.273333333333333|\n",
      "|     Crime|Film-Noir| 4.264129181084199|\n",
      "|           Film-Noir| 4.258104738154613|\n",
      "|Action|Adventure|...| 4.251655629139073|\n",
      "|Adventure|Childre...| 4.247962747380675|\n",
      "|     Drama|Film-Noir| 4.218152866242038|\n",
      "|  Film-Noir|Thriller| 4.206757438224912|\n",
      "|Crime|Film-Noir|M...|4.2020547945205475|\n",
      "|Comedy|Mystery|Ro...| 4.184158415841584|\n",
      "|Comedy|Drama|Musical| 4.179785330948121|\n",
      "|Comedy|Mystery|Th...| 4.168154761904762|\n",
      "|  Action|Crime|Drama| 4.151277918489523|\n",
      "|Action|Adventure|...| 4.147826086956521|\n",
      "|Comedy|Drama|Western| 4.141263940520446|\n",
      "|Crime|Film-Noir|M...| 4.126734158230221|\n",
      "|Action|Sci-Fi|Thr...| 4.125824175824176|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Genre with maximum average rating: \n",
      " Row(Genre='Animation|Comedy|Thriller', Avg_Rating=4.473837209302325)\n"
     ]
    }
   ],
   "source": [
    "a = test.rdd.groupByKey().mapValues(lambda x: sum(x) / len(x))\n",
    "c = sqlContext.createDataFrame(a).orderBy('_2',ascending = False)\n",
    "c = c.selectExpr(\"_1 as Genre\",\"_2 as Avg_Rating\")\n",
    "c.show()\n",
    "maxx = c.rdd.max(key=lambda x:x[1])\n",
    "print(\"Genre with maximum average rating: \\n\",maxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "G__yHQtcHNHU",
    "outputId": "72cdbd7d-aabd-47f4-e83c-5eb745ee2d9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|UserID|Rating|\n",
      "+------+------+\n",
      "|  1090|     3|\n",
      "|  1090|     3|\n",
      "|  1090|     4|\n",
      "|  1090|     3|\n",
      "|  1090|     4|\n",
      "|  1090|     4|\n",
      "|  1090|     3|\n",
      "|  1090|     3|\n",
      "|  1090|     4|\n",
      "|  1090|     3|\n",
      "|  1090|     3|\n",
      "|  1090|     3|\n",
      "|  1090|     4|\n",
      "|  1090|     2|\n",
      "|  1090|     4|\n",
      "|  1090|     2|\n",
      "|  1090|     3|\n",
      "|  1090|     4|\n",
      "|  1090|     3|\n",
      "|  1090|     3|\n",
      "+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "u_rat = merged.groupby('UserID').agg(countDistinct(\"MovieID\"))\n",
    "u_rat = u_rat.filter(u_rat['count(DISTINCT MovieID)'] > 40)\n",
    "merged = merged.join(u_rat,\"UserID\",\"inner\")\n",
    "columns_to_drop = ['MovieID', 'Title','Genre','count(DISTINCT MovieID)',\n",
    "                   'Timestamp']\n",
    "test = merged.drop(*columns_to_drop)\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "v8CIhr86IqsO",
    "outputId": "2d76eb6c-4c97-43f8-93b7-2dba67d31b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|UserID|        Avg_Rating|\n",
      "+------+------------------+\n",
      "|  3598|1.0153846153846153|\n",
      "|  4486|1.0588235294117647|\n",
      "|  2744|1.3043478260869565|\n",
      "|  4539| 1.815126050420168|\n",
      "|  5850|1.8448275862068966|\n",
      "|  5334|1.9272727272727272|\n",
      "|  5686|2.0452830188679245|\n",
      "|  3209|2.0608695652173914|\n",
      "|  1608|2.0833333333333335|\n",
      "|  4575|             2.088|\n",
      "|  4916| 2.088235294117647|\n",
      "|  1747| 2.138888888888889|\n",
      "|  1761|  2.15929203539823|\n",
      "|  1340|2.1627329192546583|\n",
      "|   163|2.1828793774319064|\n",
      "|  1100|2.1988188976377954|\n",
      "|  5039| 2.202777777777778|\n",
      "|  2106|2.2455555555555557|\n",
      "|  1630| 2.264957264957265|\n",
      "|   203|2.2913385826771653|\n",
      "+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "User with minimum average rating: \n",
      " Row(UserID='3598', Avg_Rating=1.0153846153846153)\n"
     ]
    }
   ],
   "source": [
    "test = test.withColumn(\"Rating\", test[\"Rating\"].cast(IntegerType()))\n",
    "a = test.rdd.groupByKey().mapValues(lambda x: sum(x) / len(x))\n",
    "c = sqlContext.createDataFrame(a).orderBy('_2',ascending = True)\n",
    "c = c.selectExpr(\"_1 as UserID\",\"_2 as Avg_Rating\")\n",
    "c.show()\n",
    "minn = c.rdd.min(key=lambda x:x[1])\n",
    "print(\"User with minimum average rating: \\n\",minn)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise-8.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
